#!/usr/bin/env python3
"""
Color-Only Point Cloud Generator
Creates a sparse point cloud from camera poses and color images
when depth data is unavailable or invalid.
"""
import numpy as np
import open3d as o3d
import json
from pathlib import Path
import cv2


def generate_colored_camera_trajectory(frames_json_path, output_path):
    """
    Generate a colored point cloud showing camera trajectory.
    Each camera position is represented by colored points.
    """
    with open(frames_json_path, 'r') as f:
        data = json.load(f)
    
    frames = data['frames']
    
    # Extract camera positions
    points = []
    colors = []
    
    for i, frame in enumerate(frames):
        # Get camera position from pose
        pose = frame['pose']
        position = pose['position']
        
        points.append(position)
        
        # Color gradient based on frame index (blue -> red)
        t = i / max(len(frames) - 1, 1)
        color = [1 - t, 0, t]  # Red to Blue
        colors.append(color)
    
    # Create point cloud
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(np.array(points))
    pcd.colors = o3d.utility.Vector3dVector(np.array(colors))
    
    # Save
    o3d.io.write_point_cloud(output_path, pcd)
    print(f"✓ Saved camera trajectory: {output_path}")
    print(f"  Cameras: {len(points)}")
    
    return pcd


def create_color_only_reconstruction_guide(scan_dir):
    """
    Create a guide explaining color-only reconstruction options.
    """
    scan_path = Path(scan_dir)
    guide_path = scan_path / "COLOR_ONLY_OPTIONS.md"
    
    guide_text = """# Color-Only Reconstruction Guide

WARNING: Depth data is invalid/unavailable - All depth pixels have identical values.

This typically happens when:
- Poor lighting conditions
- Surfaces are too smooth/glossy (no texture)
- Scene is beyond depth sensor range (>2m for Quest 3)

## Available Options:

### 1. NerfStudio (RECOMMENDED)
**Best for:** High-quality 3D reconstruction
```bash
# Already exported! Just run:
ns-train splatfacto --data "PATH_TO_THIS_FOLDER"
```
NerfStudio doesn't require depth - it will reconstruct from color images + poses.

### 2. COLMAP (Structure-from-Motion)
**Best for:** Traditional photogrammetry
```bash
colmap automatic_reconstructor \\
  --image_path color/ \\
  --workspace_path colmap_output/
```

### 3. Simple Camera Trajectory Visualization
**Best for:** Viewing scan path
- Open camera_trajectory.ply in MeshLab or CloudCompare

### 4. Re-scan with Better Conditions
**Tips:**
- Use bright, diffuse lighting (avoid direct sunlight)
- Scan textured surfaces (posters, furniture work better than white walls)
- Stay within 0.5-1.5m from target
- Move slowly and smoothly

---
Generated by QuestGear 3D Studio
"""
    
    with open(guide_path, 'w', encoding='utf-8') as f:
        f.write(guide_text)
    
    print(f"Created guide: {guide_path}")
    return str(guide_path)


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python generate_color_only.py <scan_directory>")
        print("Example: python generate_color_only.py C:\\Users\\...\\Scan_YYYYMMDD_HHMMSS")
        sys.exit(1)
    
    scan_dir = sys.argv[1]
    frames_json = Path(scan_dir) / "frames.json"
    
    if not frames_json.exists():
        print(f"❌ frames.json not found in {scan_dir}")
        sys.exit(1)
    
    # Generate trajectory
    output_ply = Path(scan_dir) / "camera_trajectory.ply"
    generate_colored_camera_trajectory(str(frames_json), str(output_ply))
    
    # Create guide
    create_color_only_reconstruction_guide(scan_dir)
    
    print("\n" + "="*60)
    print("✅ Color-only artifacts generated!")
    print("="*60)
    print(f"\nCheck {scan_dir} for:")
    print("  - camera_trajectory.ply (visualize in MeshLab/CloudCompare)")
    print("  - COLOR_ONLY_OPTIONS.md (next steps)")
